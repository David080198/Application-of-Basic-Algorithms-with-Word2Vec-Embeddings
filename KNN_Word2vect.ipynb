{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321080cf-aa7f-4f50-ac1a-43ac04f9a198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.005304 -0.000351  0.009146  0.001222  0.000837  0.000679  0.002596   \n",
      "1  0.005822 -0.001430  0.005763 -0.000934  0.001667  0.002727  0.002312   \n",
      "2  0.005677 -0.001388  0.006611 -0.000376  0.001571  0.002148  0.002315   \n",
      "3  0.005591 -0.000593  0.007317  0.000085  0.001058  0.002057  0.002370   \n",
      "4  0.005759 -0.001416  0.006556 -0.000601  0.001408  0.002183  0.002204   \n",
      "\n",
      "          7         8         9  ...      9991      9992      9993      9994  \\\n",
      "0  0.001184 -0.009555 -0.012777  ...  0.007869  0.001042  0.002984 -0.003099   \n",
      "1  0.001790 -0.005621 -0.008318  ...  0.007357  0.001073  0.002427 -0.003125   \n",
      "2  0.001649 -0.006561 -0.009504  ...  0.006310  0.000807  0.001612 -0.002902   \n",
      "3  0.001474 -0.007549 -0.010247  ...  0.008613  0.001397  0.003397 -0.003345   \n",
      "4  0.001563 -0.006522 -0.009243  ...  0.006848  0.000772  0.001602 -0.002939   \n",
      "\n",
      "       9995      9996      9997      9998      9999      cat_one_hot  \n",
      "0  0.002239  0.003657  0.001547  0.002798  0.005470  [1, 0, 0, 0, 0]  \n",
      "1  0.002160  0.002965  0.001466  0.002048  0.004788  [1, 0, 0, 0, 0]  \n",
      "2  0.004524  0.000648 -0.000027  0.000561  0.004277  [1, 0, 0, 0, 0]  \n",
      "3  0.000639  0.004846  0.002712  0.003930  0.005484  [1, 0, 0, 0, 0]  \n",
      "4  0.003491  0.001261  0.000595  0.000685  0.003932  [1, 0, 0, 0, 0]  \n",
      "\n",
      "[5 rows x 10001 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv('word2vect.csv')\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame para verificar que se haya cargado correctamente\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c84b37ce-b216-4d5c-a2b0-e626c0b74488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from joblib import dump\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def crear_directorio(nombre_carpeta):\n",
    "    directorio_actual = os.getcwd()\n",
    "    print(\"El directorio actual es:\", directorio_actual)\n",
    "    ruta_nueva_carpeta = os.path.join(directorio_actual, nombre_carpeta)\n",
    "    # Verificar si la carpeta ya existe\n",
    "    if not os.path.exists(ruta_nueva_carpeta):\n",
    "        # Crear la carpeta si no existe\n",
    "        os.mkdir(ruta_nueva_carpeta)\n",
    "        print(\"Se creó la carpeta\", nombre_carpeta, \"en\", directorio_actual)\n",
    "    else:\n",
    "        print(\"La carpeta\", nombre_carpeta, \"ya existe en\", directorio_actual)\n",
    "\n",
    "    ruta_modificada = ruta_nueva_carpeta.replace(\"\\\\\",\"/\")\n",
    "    return ruta_modificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f61fba-c6da-4a34-811d-ff1827dbd9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classification(dataset,n_neighbors,test_size_1=None, cv=None):\n",
    "    # Separar las características (X) de las etiquetas (y)\n",
    "    validacion = \"\"\n",
    "    X = dataset.drop('cat_one_hot', axis=1)  # Eliminar la columna 'cat_one_hot' para obtener las características\n",
    "    y = dataset['cat_one_hot']  # Obtener solo la columna 'cat_one_hot' para obtener las etiquetas\n",
    "\n",
    "    if test_size_1:\n",
    "        # Dividir el conjunto de datos en conjunto de entrenamiento y conjunto de prueba\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_1, random_state=42)\n",
    "        \n",
    "        # Inicializar el modelo de regresión logística para clasificación multiclase\n",
    "        modelo_knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "        \n",
    "        # Entrenar el modelo de regresión logística\n",
    "        modelo_knn.fit(X_train, y_train)\n",
    "        \n",
    "        # Hacer predicciones con el modelo entrenado\n",
    "        predicciones = modelo_knn.predict(X_test)\n",
    "        \n",
    "        # Evaluar el rendimiento del modelo\n",
    "        exactitud = accuracy_score(y_test, predicciones)\n",
    "        precision = precision_score(y_test, predicciones, average='weighted')\n",
    "        recall = recall_score(y_test, predicciones, average='weighted')\n",
    "        f1 = f1_score(y_test, predicciones, average='weighted')\n",
    "        matriz_confusion = confusion_matrix(y_test, predicciones)\n",
    "        \n",
    "        # Crear un mapa de calor para la matriz de confusión\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(matriz_confusion, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title('Matriz de Confusión con test = ' + str(test_size_1))\n",
    "        plt.xlabel('Etiquetas Predichas')\n",
    "        plt.ylabel('Etiquetas Verdaderas')\n",
    "    \n",
    "        # Guardar la figura de la matriz de confusión\n",
    "        ruta_figura_incom = crear_directorio(\"KNN_val_simple_\" + str(n_neighbors) + \"_vecinos\")\n",
    "        ruta_figura = ruta_figura_incom + \"/matriz_confusion_test_\" + str(test_size_1) +  \".png\"\n",
    "        plt.savefig(ruta_figura)\n",
    "        print(\"Matriz de confusión guardada en:\", ruta_figura)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Exactitud del modelo:\", exactitud)\n",
    "        print(\"Precisión del modelo:\", precision)\n",
    "        print(\"Recall del modelo:\", recall)\n",
    "        print(\"Puntuación F1 del modelo:\", f1)\n",
    "    \n",
    "        resultados = {}\n",
    "        resultados[\"exactitud\"] = exactitud\n",
    "        resultados[\"precision\"] = precision\n",
    "        resultados[\"recall\"] = recall\n",
    "        resultados[\"f1\"] = f1\n",
    "        #resultados[\"matriz_confusion\"] = matriz_confusion\n",
    "        validacion = \"simple\"\n",
    "        ruta_para_modelo = ruta_figura_incom + \"/modelo_regresion_logistica_val_test\" + str(test_size_1) + \".pkl\"\n",
    "        with open(ruta_para_modelo, 'wb') as archivo:\n",
    "            pickle.dump(modelo_knn, archivo)\n",
    "\n",
    "    elif cv:\n",
    "        # Inicializar el modelo de regresión logística para clasificación multiclase\n",
    "        modelo_knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "        \n",
    "        # Realizar validación cruzada\n",
    "        predicciones = cross_val_predict(modelo_knn, X, y, cv=cv)\n",
    "        # Evaluar el rendimiento del modelo\n",
    "        exactitud = accuracy_score(y, predicciones)\n",
    "        precision = precision_score(y, predicciones, average='weighted')\n",
    "        recall = recall_score(y, predicciones, average='weighted')\n",
    "        f1 = f1_score(y, predicciones, average='weighted')\n",
    "        matriz_confusion = confusion_matrix(y, predicciones)\n",
    "         \n",
    "        # Crear un mapa de calor para la matriz de confusión\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(matriz_confusion, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title('Matriz de Confusión con Validación Cruzada (cv = ' + str(cv) + ')')\n",
    "        plt.xlabel('Etiquetas Predichas')\n",
    "        plt.ylabel('Etiquetas Verdaderas')\n",
    "\n",
    "        # Guardar la figura de la matriz de confusión\n",
    "        ruta_figura_incom = crear_directorio(\"KNN_val_cruz_\" + str(n_neighbors) + \"_vecinos\")\n",
    "        ruta_figura = ruta_figura_incom + \"/matriz_confusion_cv_\" + str(cv) + \".png\"\n",
    "        plt.savefig(ruta_figura)\n",
    "        print(\"Matriz de confusión guardada en:\", ruta_figura)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Exactitud media:\", exactitud)\n",
    "        print(\"Precisión media:\", precision)\n",
    "        print(\"Recall media:\", recall)\n",
    "        print(\"Puntuación F1 media:\", f1)\n",
    "\n",
    "        resultados = {}\n",
    "        resultados[\"exactitud_media\"] = exactitud\n",
    "        resultados[\"precision_media\"] = precision\n",
    "        resultados[\"recall_media\"] = recall\n",
    "        resultados[\"f1_media\"] = f1\n",
    "        validacion = \"cruz\"\n",
    "        ruta_para_modelo = ruta_figura_incom + \"/modelo_regresion_logistica_val_cruz\" + str(cv) + \".pkl\"\n",
    "        with open(ruta_para_modelo, 'wb') as archivo:\n",
    "            pickle.dump(modelo_knn, archivo)\n",
    "    else:\n",
    "        print(\"Por favor, proporciona el tamaño de prueba (test_size_1) o el número de pliegues de validación cruzada (cv).\")\n",
    "        resultados = None\n",
    "    \n",
    "    return resultados,validacion,ruta_figura_incom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae22c3c-fcd1-4855-bb53-734a7dd413ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "def almacenar_informacion(resultados_finales,validacion,ruta_figura_incom):\n",
    "    if validacion == \"simple\":\n",
    "        ruta_archivo = ruta_figura_incom + \"/regresion_logistica_val_simple.json\"\n",
    "        with open(ruta_archivo, \"w\") as archivo:\n",
    "            json.dump(resultados_finales, archivo)\n",
    "        \n",
    "        print(\"Diccionario guardado como archivo JSON en:\", ruta_archivo)\n",
    "    elif validacion == \"cruz\":\n",
    "        ruta_archivo =  ruta_figura_incom + \"/regresion_logistica_val_cruz.json\"\n",
    "        with open(ruta_archivo, \"w\") as archivo:\n",
    "            json.dump(resultados_finales, archivo)\n",
    "        \n",
    "        print(\"Diccionario guardado como archivo JSON en:\", ruta_archivo)\n",
    "\n",
    "# Inicializar una lista vacía para almacenar los valores\n",
    "lista_valores = []\n",
    "ruta_figura_incom = \"\"\n",
    "# Bucle for para generar los valores en incrementos de 0.10 hasta 0.9\n",
    "for i in range(1, 10):\n",
    "    valor = i / 10.0\n",
    "    lista_valores.append(valor)\n",
    "\n",
    "resultados_finales_val_simple = {}\n",
    "resultados_finales_val_cruz = {}\n",
    "\n",
    "\n",
    "lista = [3,5,7,9,11,13]\n",
    "\n",
    "for numero in lista: \n",
    "    experimento = 1\n",
    "    for i in lista_valores:\n",
    "        resultados_finales_val_simple[\"Experimento_LR_\" + str(experimento) + \"_test_\" + str(i)],validacion,ruta_figura_incom = knn_classification(df_junto,numero,test_size_1=i)\n",
    "        experimento = experimento + 1\n",
    "    \n",
    "    almacenar_informacion(resultados_finales_val_simple,validacion,ruta_figura_incom)\n",
    "    \n",
    "    lista = list(range(2, 11))\n",
    "    for j in lista:\n",
    "        resultados_finales_val_cruz[\"Experimento_LR_\" + str(experimento) + \"_test_\" + str(j)],validacion,ruta_figura_incom = knn_classification(df_junto,numero,cv=j)\n",
    "    \n",
    "    almacenar_informacion(resultados_finales_val_cruz,validacion,ruta_figura_incom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_1",
   "language": "python",
   "name": "gpu_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
